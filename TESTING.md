# Testing Framework for AI-Automated Error Fixing

This comprehensive testing framework is designed to enable AI agents to automatically detect, analyze, and fix errors in the TinderaWebPedlerV0 codebase.

## üéØ Overview

The testing framework includes:
- **Unit Tests** - Individual component and hook testing
- **Integration Tests** - Cross-component functionality testing  
- **Regression Tests** - Critical functionality protection
- **AI-Specific Tests** - Automated error pattern detection and fixing
- **Smart Mocking** - Realistic data simulation for Supabase operations

## üöÄ Quick Start

### Installation
```bash
# Install testing dependencies
npm install

# Validate test setup
node tests/validate-setup.js

# Run all tests
npm test
```

### Available Test Commands
```bash
npm run test                 # Run all tests
npm run test:watch          # Run tests in watch mode
npm run test:coverage       # Run with coverage report
npm run test:unit           # Run unit tests only
npm run test:integration    # Run integration tests only
npm run test:regression     # Run regression tests only
npm run test:ai-fix         # Run AI automated fix tests
```

## üß† AI-Automated Error Fixing

### How It Works

1. **Error Detection**: Tests capture errors with detailed context
2. **Pattern Analysis**: AI analyzer categorizes errors by common patterns
3. **Fix Generation**: Automated suggestions for resolving errors
4. **Learning**: System learns from error patterns to prevent future issues

### Error Categories

The AI system recognizes these error patterns:

| Category | Description | Auto-Fixable | Example Fix |
|----------|-------------|--------------|-------------|
| `NULL_ACCESS` | Property access on null/undefined | ‚úÖ | `obj?.prop` or null checks |
| `FUNCTION_ERROR` | Undefined function calls | ‚úÖ | Import fixes or optional calls |
| `IMPORT_ERROR` | Missing module imports | ‚úÖ | Path corrections or installations |
| `TYPE_ERROR` | Type-related errors | ‚úÖ | Type guards or default values |
| `ASSERTION_ERROR` | Test expectation failures | ‚úÖ | Updated expectations or mocks |
| `TIMEOUT_ERROR` | Test timeout issues | ‚úÖ | Timeout adjustments or mocking |

### AI Error Reports

After running tests, check `tests/reports/` for:
- `ai-error-report.json` - Detailed error analysis
- `ai-fix-suggestions.json` - Automated fix recommendations

## üìÅ Project Structure

```
tests/
‚îú‚îÄ‚îÄ setup.ts                          # Global test configuration
‚îú‚îÄ‚îÄ validate-setup.js                 # Test framework validation
‚îÇ
‚îú‚îÄ‚îÄ mocks/
‚îÇ   ‚îî‚îÄ‚îÄ supabase.ts                   # Supabase client mocks
‚îÇ
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ ai-error-reporter.js          # Custom Jest reporter for AI
‚îÇ   ‚îî‚îÄ‚îÄ ai-test-helpers.ts            # AI testing utilities
‚îÇ
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îî‚îÄ‚îÄ hooks/
‚îÇ       ‚îú‚îÄ‚îÄ useProducts.test.ts       # Product hook tests
‚îÇ       ‚îî‚îÄ‚îÄ useCategories.test.ts     # Category hook tests
‚îÇ
‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îî‚îÄ‚îÄ dashboard.test.tsx            # Dashboard component tests
‚îÇ
‚îú‚îÄ‚îÄ regression/
‚îÇ   ‚îî‚îÄ‚îÄ critical-functionality.test.tsx # Regression protection
‚îÇ
‚îú‚îÄ‚îÄ ai-fix/
‚îÇ   ‚îî‚îÄ‚îÄ automated-fixes.test.tsx      # AI fix pattern tests
‚îÇ
‚îî‚îÄ‚îÄ reports/                          # Generated AI reports
    ‚îú‚îÄ‚îÄ ai-error-report.json
    ‚îî‚îÄ‚îÄ ai-fix-suggestions.json
```

## üîß Configuration Files

### Jest Configuration (`jest.config.js`)
- Next.js integration
- TypeScript support
- AI error reporting
- Coverage thresholds
- Custom module mapping

### Test Setup (`tests/setup.ts`)
- Global mocks (Router, window objects)
- Supabase environment variables
- AI error tracking
- Test utilities

## üé≠ Mocking Strategy

### Supabase Mocks
Comprehensive mocks for all Supabase operations:
```typescript
// Example usage
import { mockSupabaseClient, mockProducts } from '../mocks/supabase'

// Automatic query building with realistic data
const products = await mockSupabaseClient
  .from('products')
  .select('*')
  .eq('category_id', '1')
```

### Smart Mocks
AI-enhanced mocks that adapt based on usage patterns:
```typescript
import { aiTestHelper } from '../utils/ai-test-helpers'

const smartMock = aiTestHelper.createSmartMock('apiCall', (args) => {
  // Auto-adjusts return values based on common patterns
  return mockData
})
```

## üìä Testing Best Practices for AI

### 1. Descriptive Test Names
```typescript
// Good - AI can understand intent
it('should handle null product data gracefully', () => {})

// Better - AI can categorize error type
it('AI-FIX: Should detect and fix null property access', () => {})
```

### 2. Error Context Tracking
```typescript
const testFn = aiTestHelper.wrapTest(async () => {
  // Test implementation
}, 'test-name', { 
  component: 'ProductCard',
  expectedError: 'NULL_ACCESS'
})
```

### 3. Self-Healing Test Patterns
```typescript
it('should gracefully handle API failures', async () => {
  try {
    // Potentially failing operation
    await riskyOperation()
  } catch (error) {
    // AI-generated fix applied
    const fallbackResult = applyFallbackStrategy()
    expect(fallbackResult).toBeDefined()
  }
})
```

### 4. Regression Protection
```typescript
describe('REGRESSION: Critical POS Functionality', () => {
  it('REGRESSION: Cart operations must work correctly', () => {
    // Critical functionality that must never break
  })
})
```

## üîç Debugging and Troubleshooting

### Common Issues and AI Fixes

**Issue**: `Cannot read property 'name' of undefined`
```typescript
// AI Auto-Fix
const safeName = product?.name || 'Unknown Product'
```

**Issue**: `Module not found: '@/components/Button'`
```typescript
// AI Auto-Fix: Check import path
import Button from '@/components/ui/button'
```

**Issue**: `Expected 1 but received undefined`
```typescript
// AI Auto-Fix: Update mock return value
mockFunction.mockReturnValue(1)
```

### Manual Debugging
```bash
# Run tests with verbose output
npm test -- --verbose

# Run specific test file
npm test -- useProducts.test.ts

# Run with coverage
npm run test:coverage

# Debug AI error patterns
npm run test:ai-fix -- --verbose
```

## üìà Monitoring and Metrics

### Coverage Targets
- **Branches**: 70%+
- **Functions**: 70%+
- **Lines**: 70%+
- **Statements**: 70%+

### AI Success Metrics
- **Auto-fixable Error Rate**: Track percentage of errors AI can fix
- **Pattern Recognition**: Monitor common error categories
- **Fix Accuracy**: Measure success rate of AI-suggested fixes

### Reports Location
- Coverage: `coverage/lcov-report/index.html`
- AI Analysis: `tests/reports/ai-error-report.json`
- Fix Suggestions: `tests/reports/ai-fix-suggestions.json`

## ü§ñ AI Agent Instructions

For AI agents working with this codebase:

1. **Before Making Changes**: Run `npm run test:regression` to establish baseline
2. **After Changes**: Run full test suite and analyze AI error reports
3. **Error Handling**: Use patterns from `ai-test-helpers.ts` for consistent error detection
4. **Fix Application**: Implement suggestions from `ai-fix-suggestions.json`
5. **Learning**: Review error patterns to improve future code generation

### AI-Friendly Error Messages
The framework generates structured error messages that AI can easily parse:
```json
{
  "error": "Cannot read property 'name' of undefined",
  "category": "NULL_ACCESS",
  "autoFixable": true,
  "suggestion": "Add null check: obj?.name || defaultValue"
}
```

## üîÑ Continuous Integration

### GitHub Actions Integration
```yaml
# Example CI configuration
- name: Run Tests with AI Analysis
  run: |
    npm run test:coverage
    npm run test:ai-fix
    
- name: Upload AI Reports
  uses: actions/upload-artifact@v2
  with:
    name: ai-test-reports
    path: tests/reports/
```

### Pre-commit Hooks
```bash
# Install husky for pre-commit testing
npm install --save-dev husky

# Add pre-commit hook
npx husky add .husky/pre-commit "npm run test:regression"
```

## üìö Additional Resources

- [Jest Documentation](https://jestjs.io/docs/getting-started)
- [React Testing Library](https://testing-library.com/docs/react-testing-library/intro/)
- [Testing Next.js](https://nextjs.org/docs/testing)
- [Supabase Testing Guide](https://supabase.com/docs/guides/getting-started/local-development)

## üÜò Support

If you encounter issues:

1. Run `node tests/validate-setup.js` to check configuration
2. Review AI error reports for automated suggestions
3. Check the console for detailed error messages with fix recommendations
4. Use AI test helpers for consistent error patterns

Remember: This framework is designed to learn and improve. The more you use it, the better it becomes at detecting and fixing errors automatically!